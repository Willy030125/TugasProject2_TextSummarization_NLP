{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vBH9puPPbncX","outputId":"745132ef-620e-44e4-d583-788320bc11c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri Jul  5 11:12:55 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  NVIDIA GeForce RTX 3090        Off | 00000000:01:00.0 Off |                  N/A |\n","| 30%   45C    P8               7W / 370W |     35MiB / 24576MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|    0   N/A  N/A       983      G   ...illy030125/JuiceServer/Renderer_Win        4MiB |\n","|    0   N/A  N/A      1064      G   /usr/lib/xorg/Xorg                            9MiB |\n","|    0   N/A  N/A      1234      G   /usr/bin/gnome-shell                          8MiB |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oEy9B3jF4ala","outputId":"0efe04f6-40a6-4fdc-a2ae-ed46f4b0f41f"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-05 11:12:58.376015: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-07-05 11:12:58.405519: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from datasets import load_dataset, load_from_disk\n","from datasets import Dataset, DatasetDict, concatenate_datasets\n","from transformers import BertTokenizer, BertModel, EncoderDecoderModel, TrainingArguments, Trainer, DataCollatorForSeq2Seq"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WsAOmoGYcE9I","outputId":"e1f6b0ad-f7d7-4573-8cb4-f1e814042160"},"outputs":[{"name":"stdout","output_type":"stream","text":["train data: 193883\n","eval data: 10972\n"]}],"source":["import glob\n","import json\n","import re\n","\n","train_file = glob.glob(\"liputan6_data/canonical/train/*.json\")\n","train_file.sort(key=lambda f: int(re.sub('\\D', '', f)))\n","\n","eval_file = glob.glob(\"liputan6_data/canonical/test/*.json\")\n","eval_file.sort(key=lambda f: int(re.sub('\\D', '', f)))\n","\n","train_data = []\n","eval_data = []\n","\n","for i in train_file:\n","  with open(i, \"r\", encoding=\"utf-8\") as f:\n","    d = json.load(f)\n","    train_data.append(d)\n","\n","for i in eval_file:\n","  with open(i, \"r\", encoding=\"utf-8\") as f:\n","    d = json.load(f)\n","    eval_data.append(d)\n","\n","print(f\"train data: {len(train_data)}\")\n","print(f\"eval data: {len(eval_data)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMitYaDFf1J_","outputId":"9fd5adcf-55b1-4061-c269-74485e37c0f0"},"outputs":[{"data":{"text/plain":["dict_keys(['id', 'url', 'clean_article', 'clean_summary', 'extractive_summary'])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_data[0].keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EY0C3WQXi_W4"},"outputs":[],"source":["train_data = train_data[:50000]\n","eval_data = eval_data[:5000]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eGoxXd7nf4MH"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","def custom_join(words):\n","  result = ' '.join(words)\n","  result = result.replace(\"Liputan6 . com\", \"Liputan6.com\")\n","  result = result.replace(\" , \", \", \")\n","  result = result.replace(\" . \", \". \")\n","  result = result.replace(\" ( \", \" (\")\n","  result = result.replace(\" ) \", \") \")\n","  return result\n","\n","\n","def make_dataset_df(data):\n","  clean_article = []\n","  clean_summary = []\n","\n","  for item in data:\n","    clean_article_sentence = []\n","    for arr in item['clean_article']:\n","      clean_article_sentence.extend(arr)\n","    joined_str1 = custom_join(clean_article_sentence)\n","    clean_article.append(joined_str1)\n","\n","    clean_summary_sentence = []\n","    for arr in item['clean_summary']:\n","      clean_summary_sentence.extend(arr)\n","    joined_str2 = custom_join(clean_summary_sentence)\n","    clean_summary.append(joined_str2)\n","\n","  df = pd.DataFrame({'clean_article': clean_article, 'clean_summary': clean_summary})\n","  return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NrVxppEoh5WY"},"outputs":[],"source":["train_df = make_dataset_df(train_data)\n","eval_df = make_dataset_df(eval_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"LIOiC-s9iGs6","outputId":"dc7ae4ad-633f-4c70-c82f-c8922648a52f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>clean_article</th>\n","      <th>clean_summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Liputan6.com, Ambon : Partai Bulan Bintang wil...</td>\n","      <td>Konflik Ambon telah berlangsung selama tiga ta...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Liputan6.com, Denpasar : Berbeda dengan sebagi...</td>\n","      <td>Masyarakat Bali merayakan Tahun Baru dengan tr...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Liputan6.com, Jakarta : Partai Keadilan bertek...</td>\n","      <td>Partai Keadilan menargetkan tambahan sejuta pe...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Liputan6.com, Jakarta : Sekitar Rumah Makan Ay...</td>\n","      <td>Pascaledakan granat di depan Rumah Makan Ayam ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Liputan6.com, Jambi : Ratusan hektare sawah di...</td>\n","      <td>Bencana Banjir di Jambi, juga mengakibatkan ra...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>Liputan6.com, Semaranfa : Pelantikan Wali Kota...</td>\n","      <td>Pelantikan Wali Kota Semarang di Balai Kota Se...</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>Liputan6.com, Serang : Sekelompok orang yang m...</td>\n","      <td>Pengunjuk rasa yang tergabung dalam Gerakan Ma...</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>Liputan6.com, Jakarta : Lebih dari seribu eks ...</td>\n","      <td>Ribuan bekas karyawan PT DI berunjuk rasa di d...</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>Liputan6.com, Purwakarta : Kelangkaan minyak t...</td>\n","      <td>Warga Purwakarta, Jawa Barat, sudah satu bulan...</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>Liputan6.com, Tangerang : Kawasan Legok, Tange...</td>\n","      <td>Sejak merebaknya kasus flu burung di berbagai ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                           clean_article  \\\n","0      Liputan6.com, Ambon : Partai Bulan Bintang wil...   \n","1      Liputan6.com, Denpasar : Berbeda dengan sebagi...   \n","2      Liputan6.com, Jakarta : Partai Keadilan bertek...   \n","3      Liputan6.com, Jakarta : Sekitar Rumah Makan Ay...   \n","4      Liputan6.com, Jambi : Ratusan hektare sawah di...   \n","...                                                  ...   \n","49995  Liputan6.com, Semaranfa : Pelantikan Wali Kota...   \n","49996  Liputan6.com, Serang : Sekelompok orang yang m...   \n","49997  Liputan6.com, Jakarta : Lebih dari seribu eks ...   \n","49998  Liputan6.com, Purwakarta : Kelangkaan minyak t...   \n","49999  Liputan6.com, Tangerang : Kawasan Legok, Tange...   \n","\n","                                           clean_summary  \n","0      Konflik Ambon telah berlangsung selama tiga ta...  \n","1      Masyarakat Bali merayakan Tahun Baru dengan tr...  \n","2      Partai Keadilan menargetkan tambahan sejuta pe...  \n","3      Pascaledakan granat di depan Rumah Makan Ayam ...  \n","4      Bencana Banjir di Jambi, juga mengakibatkan ra...  \n","...                                                  ...  \n","49995  Pelantikan Wali Kota Semarang di Balai Kota Se...  \n","49996  Pengunjuk rasa yang tergabung dalam Gerakan Ma...  \n","49997  Ribuan bekas karyawan PT DI berunjuk rasa di d...  \n","49998  Warga Purwakarta, Jawa Barat, sudah satu bulan...  \n","49999  Sejak merebaknya kasus flu burung di berbagai ...  \n","\n","[50000 rows x 2 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"OarV353aiJkb","outputId":"55b6a0c6-3717-4a5d-d1d9-a8a8a5e0a637"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>clean_article</th>\n","      <th>clean_summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Liputan6.com, Jakarta : Kepolisian Daerah Riau...</td>\n","      <td>Kapolda Riau baru Brigjen Pol. Johny Yodjana b...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Liputan6.com, Jakarta : Bank Indonesia dinilai...</td>\n","      <td>Kendati Bank Sentral AS menurunkan suku bungan...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Liputan6.com, Jakarta : Berbagai kendala mengh...</td>\n","      <td>Pemerintah bermaksud akan lebih mengandalkan s...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Liputan6.com, Jakarta : Penghapusan beberapa p...</td>\n","      <td>Revisi Kepmennaker Nomor 78 Tahun 2001, dinila...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Liputan6.com, Jakarta : Operasi Sadar Jaya yan...</td>\n","      <td>Polisi menangkap 32 pengunjung Diskotik Mileni...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>Liputan6.com, Jakarta : Pemerintah tak akan me...</td>\n","      <td>Pemerintah melarang Kapal Tampa yang berisi ra...</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>Liputan6.com, Jambi : Ini potret perpecahan di...</td>\n","      <td>Ketua DPC KNPI Jambi Rudi Ardiansyah yang memi...</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>Liputan6.com, Padang : Pelantikan lima penguru...</td>\n","      <td>Pelantikan lima pengurus Dewan Pimpinan Daerah...</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>Liputan6.com, Semarang : Solar mengalami kelan...</td>\n","      <td>Bahan bakar minyak jenis solar di jalur Pantai...</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>Liputan6.com, Jakarta : Departemen Agama mesti...</td>\n","      <td>Pemerintah harus memisahkan Ditjen Bimas Budha...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows × 2 columns</p>\n","</div>"],"text/plain":["                                          clean_article  \\\n","0     Liputan6.com, Jakarta : Kepolisian Daerah Riau...   \n","1     Liputan6.com, Jakarta : Bank Indonesia dinilai...   \n","2     Liputan6.com, Jakarta : Berbagai kendala mengh...   \n","3     Liputan6.com, Jakarta : Penghapusan beberapa p...   \n","4     Liputan6.com, Jakarta : Operasi Sadar Jaya yan...   \n","...                                                 ...   \n","4995  Liputan6.com, Jakarta : Pemerintah tak akan me...   \n","4996  Liputan6.com, Jambi : Ini potret perpecahan di...   \n","4997  Liputan6.com, Padang : Pelantikan lima penguru...   \n","4998  Liputan6.com, Semarang : Solar mengalami kelan...   \n","4999  Liputan6.com, Jakarta : Departemen Agama mesti...   \n","\n","                                          clean_summary  \n","0     Kapolda Riau baru Brigjen Pol. Johny Yodjana b...  \n","1     Kendati Bank Sentral AS menurunkan suku bungan...  \n","2     Pemerintah bermaksud akan lebih mengandalkan s...  \n","3     Revisi Kepmennaker Nomor 78 Tahun 2001, dinila...  \n","4     Polisi menangkap 32 pengunjung Diskotik Mileni...  \n","...                                                 ...  \n","4995  Pemerintah melarang Kapal Tampa yang berisi ra...  \n","4996  Ketua DPC KNPI Jambi Rudi Ardiansyah yang memi...  \n","4997  Pelantikan lima pengurus Dewan Pimpinan Daerah...  \n","4998  Bahan bakar minyak jenis solar di jalur Pantai...  \n","4999  Pemerintah harus memisahkan Ditjen Bimas Budha...  \n","\n","[5000 rows x 2 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["eval_df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"_YdiK0wUmp_Y","outputId":"b00a9cc7-3b09-4e0d-8b54-8cf12a7c821d"},"outputs":[{"data":{"text/plain":["'Liputan6.com, Ambon : Partai Bulan Bintang wilayah Maluku bertekad membantu pemerintah menyelesaikan konflik di provinsi tersebut. Syaratnya, penanganan penyelesaian konflik Maluku harus dimulai dari awal kerusuhan, yakni 19 Januari 1999. Demikian hasil Musyawarah Wilayah I PBB Maluku yang dimulai Sabtu pekan silam dan berakhir Senin (31/12) di Ambon. Menurut seorang fungsionaris PBB Ridwan Hasan, persoalan di Maluku bisa selesai asalkan pemerintah dan aparat keamanan serius menangani setiap persoalan di Maluku secara komprehensif dan bijaksana. Itulah sebabnya, PBB wilayah Maluku akan menjadikan penyelesaian konflik sebagai agenda utama partai. PBB Maluku juga akan mendukung penegakan hukum secara terpadu dan tanpa pandang bulu. Siapa saja yang melanggar hukum harus ditindak. Ridwan berharap, Ketua PBB Maluku yang baru, Ali Fauzi, dapat menindak lanjuti agenda politik partai yang telah diamanatkan dan mau mendukung penegakan hukum di Maluku. (ULF/Sahlan Heluth) .'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train_df['clean_article'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"naVisbl4mug-","outputId":"d9732e79-4161-4d71-ba0a-acb3e635282c"},"outputs":[{"data":{"text/plain":["'Konflik Ambon telah berlangsung selama tiga tahun. Partai Bulan Bintang wilayah Maluku siap membantu pemerintah menyelesaikan kasus di provinsi tersebut .'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train_df['clean_summary'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZEPkzeVf3Zk"},"outputs":[],"source":["train_dataset = Dataset.from_pandas(train_df)\n","eval_dataset = Dataset.from_pandas(eval_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RIZpPox_uM-i","outputId":"65e5447f-a348-4b2c-879e-918c03476b1d"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['clean_article', 'clean_summary'],\n","    num_rows: 50000\n","})"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xaJgTLMuP8o","outputId":"39329833-ddb5-44a2-f2f3-738d6a027b09"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['clean_article', 'clean_summary'],\n","    num_rows: 5000\n","})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["eval_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XW9-dtgUuRxE"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('cahya/bert-base-indonesian-1.5G')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L6eDILTMup9Y"},"outputs":[],"source":["def tokenize_data(example):\n","    input_encoding = tokenizer(example['clean_article'], padding='max_length', truncation=True, max_length=512)\n","    target_encoding = tokenizer(example['clean_summary'], padding='max_length', truncation=True, max_length=128)\n","    return {\n","        'input_ids': input_encoding['input_ids'],\n","        'attention_mask': input_encoding['attention_mask'],\n","        'labels': target_encoding['input_ids']\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["85e7361159984bfa911e1fbda2330e53","1842d07fef234c97a1ae7c828fc19fae","969147b8bf31493bbbb7d89e0656e98e","a7707ef300e54c5fa95de1d637ffaf96","98e70f25c40a410b95e6df23222494ab","d17cf514f49e4b06b9f40d221682b691","92a615229c4a496ba41cc9bf4eeb6521","3640f38e7beb4ae084cb0e0253b79d9c","712e2117748a4179873e7fc3e7b18ecb","4c99d4003d264e2a8b24ffc342b32950","10aecbcd12cf427e9f15db12878c7a27","8b22723e8045481689225217424ecfb3","ecaeed09c32a4caa90b83782524dc468","ff5a37f79d4e4ae48ae1d46f6f73c4a3","0aea801c08eb422bb1aaaf18895aea6a","c7762f4e7a914adcb8e5145f5cb17241","aaeecdeeb6d546d6baa645f6dbed2814","4facf208d8eb4c07b300a48fa8f3fb83","af6050d99aa4427aa048dbbac7edccdb","4238279c927448aca971450c188ec2ad","059e2906913a4afcbe43f7d86a30331c","2f30f32af3bc417481fc3d6a68678e8b","fad2770e67604fbfa1c281c5a6ea6774","74f22a91ffee4a95a06e9e9d20bf358c"]},"id":"A-ZIvO00uvbb","outputId":"f499b903-1390-47e7-af74-07815056862e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fad2770e67604fbfa1c281c5a6ea6774","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/50000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74f22a91ffee4a95a06e9e9d20bf358c","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/5000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_train = train_dataset.map(tokenize_data, batched=True, num_proc=4)\n","tokenized_eval = eval_dataset.map(tokenize_data, batched=True, num_proc=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"NOeQyxLbztFi","outputId":"39c354d3-c545-4610-f50c-d71ff829958a"},"outputs":[{"data":{"text/plain":["'[PAD]'"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.pad_token"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"YJVBQ0iyz85T","outputId":"2a78d83d-780c-4ec1-9aa8-42a4d41e6922"},"outputs":[{"data":{"text/plain":["'[CLS]'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.cls_token"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ntQKDCfg1reR","outputId":"e0a248bb-129d-4edd-f7a8-37fa2f1c1d94"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/willy030125/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","Some weights of BertLMHeadModel were not initialized from the model checkpoint at cahya/bert-base-indonesian-1.5G and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# make Bert2Bert (Encoder-Decoder model)\n","model = EncoderDecoderModel.from_encoder_decoder_pretrained('cahya/bert-base-indonesian-1.5G', 'cahya/bert-base-indonesian-1.5G')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B8NI1u422VbV"},"outputs":[],"source":["# Define special tokens\n","model.config.decoder_start_token_id = tokenizer.cls_token_id\n","model.config.pad_token_id = tokenizer.pad_token_id\n","model.config.vocab_size = model.config.encoder.vocab_size"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wOErgwgS2agT","outputId":"7fd1ae20-98e7-4049-f390-5e521a176c60"},"outputs":[{"data":{"text/plain":["32000"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["model.config.encoder.vocab_size"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWsysEBf2f3W"},"outputs":[],"source":["# Set configurations for the encoder and decoder\n","model.config.encoder.max_length = 512\n","model.config.decoder.max_length = 128\n","model.config.decoder.min_length = 12\n","model.config.length_penalty = 2.0\n","model.config.early_stopping = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bhdjw2EI2oPL"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8H8Igdw2reM"},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=10,\n","    gradient_accumulation_steps=4,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=8,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    learning_rate=5e-05,\n","    logging_dir='./logs',\n","    logging_steps=100,\n","    eval_strategy='epoch',\n","    save_strategy='epoch',\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZpWP3oN52tuu"},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train,\n","    eval_dataset=tokenized_eval,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"Uo-Q8wu82xEv","outputId":"d707cfed-816f-45f3-f2ef-db7677e1a975"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2024-07-05 11:13:59,215] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/home/willy030125/Downloads/BertSummarization' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/willy030125/huggingface/2f29c273ec4f433c8d57a698f2708043\n","\n","wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","wandb: Currently logged in as: willy030125. Use `wandb login --relogin` to force relogin\n"]},{"data":{"text/html":["wandb version 0.17.4 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/willy030125/Downloads/BertSummarization/wandb/run-20240705_111407-xtzzd7p8</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/willy030125/huggingface/runs/xtzzd7p8' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/willy030125/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/willy030125/huggingface' target=\"_blank\">https://wandb.ai/willy030125/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/willy030125/huggingface/runs/xtzzd7p8' target=\"_blank\">https://wandb.ai/willy030125/huggingface/runs/xtzzd7p8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/willy030125/.venv/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3900' max='3900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3900/3900 4:13:47, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>1.047700</td>\n","      <td>0.851269</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.835300</td>\n","      <td>0.730656</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.653300</td>\n","      <td>0.606682</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.459700</td>\n","      <td>0.550588</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.414600</td>\n","      <td>0.549792</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.379000</td>\n","      <td>0.546868</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.332200</td>\n","      <td>0.554853</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.318400</td>\n","      <td>0.557019</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : fuchsia_vicuna_8211\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/willy030125/huggingface/2f29c273ec4f433c8d57a698f2708043\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epoch [50]                     : (0.2559181062060141, 9.980806142034549)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval/loss [10]                 : (0.5468683838844299, 0.8512689471244812)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval/runtime [10]              : (52.1712, 52.6349)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval/samples_per_second [10]   : (94.994, 95.838)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval/steps_per_second [10]     : (11.874, 11.98)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_loss [10]                 : (0.5468683838844299, 0.8512689471244812)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_runtime [10]              : (52.1712, 52.6349)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_samples_per_second [10]   : (94.994, 95.838)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_steps_per_second [10]     : (11.874, 11.98)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     grad_norm [39]                 : (0.6664091348648071, 1.0947462320327759)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate [39]             : (0.0, 5e-05)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [1593]                    : (0.26465365290641785, 11.13036060333252)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     total_flos                     : 3.061502154909942e+17\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/epoch [50]               : (0.2559181062060141, 9.980806142034549)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/grad_norm [39]           : (0.6664091348648071, 1.0947462320327759)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/learning_rate [39]       : (0.0, 5e-05)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/loss [39]                : (0.3167, 3.2485)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/total_flos               : 3.061502154909942e+17\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_loss               : 0.5953431080549191\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_runtime            : 15236.0888\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_samples_per_second : 32.817\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train/train_steps_per_second   : 0.256\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss                     : 0.5953431080549191\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_runtime                  : 15236.0888\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_samples_per_second       : 32.817\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_steps_per_second         : 0.256\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_n_gpu                                  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_no_sync_in_gradient_accumulation       : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_setup_devices                          : cuda:0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/accelerator_config                      : AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True, non_blocking=False, gradient_accumulation_kwargs=None)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adafactor                               : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_beta1                              : 0.9\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_beta2                              : 0.999\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_epsilon                            : 1e-08\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/auto_find_batch_size                    : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/batch_eval_metrics                      : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/bf16                                    : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/bf16_full_eval                          : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/data_seed                               : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_drop_last                    : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_num_workers                  : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_persistent_workers           : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_pin_memory                   : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_prefetch_factor              : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_backend                             : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_broadcast_buffers                   : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_bucket_cap_mb                       : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_find_unused_parameters              : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_timeout                             : 1800\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_timeout_delta                       : 0:30:00\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/debug                                   : []\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/deepspeed                               : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/deepspeed_plugin                        : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/default_optim                           : adamw_torch\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/device                                  : cuda:0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/disable_tqdm                            : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dispatch_batches                        : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/distributed_state                       : Distributed environment: NO\n","Num processes: 1\n","Process index: 0\n","Local process index: 0\n","Device: cuda\n","\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_eval                                 : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_predict                              : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_train                                : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_accumulation_steps                 : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_batch_size                         : 8\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_delay                              : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_do_concat_batches                  : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_steps                              : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_strategy                           : IntervalStrategy.EPOCH\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/evaluation_strategy                     : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16                                    : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_backend                            : auto\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_full_eval                          : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_opt_level                          : O1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/framework                               : pt\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp                                    : []\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_config                             : {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_min_num_params                     : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_transformer_layer_cls_to_wrap      : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/full_determinism                        : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_accumulation_steps             : 4\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_checkpointing                  : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_checkpointing_kwargs           : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/greater_is_better                       : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/group_by_length                         : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/half_precision_backend                  : auto\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_always_push                         : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_model_id                            : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_private_repo                        : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_strategy                            : HubStrategy.EVERY_SAVE\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_token                               : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ignore_data_skip                        : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/include_inputs_for_metrics              : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/include_num_input_tokens_seen           : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/include_tokens_per_second               : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/jit_mode_eval                           : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/label_names                             : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/label_smoothing_factor                  : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/learning_rate                           : 5e-05\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/length_column_name                      : length\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/load_best_model_at_end                  : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/local_process_index                     : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/local_rank                              : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_level                               : passive\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_level_replica                       : warning\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_on_each_node                        : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_dir                             : ./logs\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_first_step                      : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_nan_inf_filter                  : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_steps                           : 100\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_strategy                        : IntervalStrategy.STEPS\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/lr_scheduler_kwargs                     : {}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/lr_scheduler_type                       : SchedulerType.LINEAR\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/max_grad_norm                           : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/max_steps                               : -1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/metric_for_best_model                   : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/mp_parameters                           : \n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/n_gpu                                   : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/neftune_noise_alpha                     : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/no_cuda                                 : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/num_train_epochs                        : 10\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim                                   : OptimizerNames.ADAMW_TORCH\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim_args                              : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim_target_modules                    : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/output_dir                              : ./results\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/overwrite_output_dir                    : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/parallel_mode                           : ParallelMode.NOT_PARALLEL\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/past_index                              : -1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_device_eval_batch_size              : 8\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_device_train_batch_size             : 32\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_gpu_eval_batch_size                 : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_gpu_train_batch_size                : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/place_model_on_device                   : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/prediction_loss_only                    : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/process_index                           : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub                             : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_model_id                    : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_organization                : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_token                       : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ray_scope                               : last\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/remove_unused_columns                   : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/report_to                               : ['comet_ml', 'tensorboard', 'wandb']\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/restore_callback_states_from_checkpoint : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/resume_from_checkpoint                  : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/run_name                                : ./results\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_on_each_node                       : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_only_model                         : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_safetensors                        : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_steps                              : 500\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_strategy                           : IntervalStrategy.EPOCH\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_total_limit                        : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/seed                                    : 42\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/should_log                              : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/should_save                             : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/skip_memory_metrics                     : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/split_batches                           : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tf32                                    : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile                           : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile_backend                   : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile_mode                      : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torchdynamo                             : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tpu_metrics_debug                       : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tpu_num_cores                           : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/train_batch_size                        : 32\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_cpu                                 : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_ipex                                : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_legacy_prediction_loop              : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_mps_device                          : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/warmup_ratio                            : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/warmup_steps                            : 500\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/weight_decay                            : 0.01\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/world_size                              : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_attn_implementation                  : eager\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_attn_implementation_internal         : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_auto_class                           : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_commit_hash                          : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_name_or_path                         : \n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/add_cross_attention                   : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/architectures                         : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/attribute_map                         : {}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bad_words_ids                         : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/begin_suppress_tokens                 : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bos_token_id                          : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/chunk_size_feed_forward               : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/cross_attention_hidden_size           : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/decoder                               : BertConfig {\n","  \"_name_or_path\": \"cahya/bert-base-indonesian-1.5G\",\n","  \"add_cross_attention\": true,\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": true,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_length\": 128,\n","  \"max_position_embeddings\": 512,\n","  \"min_length\": 12,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.41.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/decoder_start_token_id                : 3\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/diversity_penalty                     : 0.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/do_sample                             : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/early_stopping                        : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/encoder                               : BertConfig {\n","  \"_name_or_path\": \"cahya/bert-base-indonesian-1.5G\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_length\": 512,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.41.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 32000\n","}\n","\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/encoder_no_repeat_ngram_size          : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/eos_token_id                          : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/exponential_decay_length_penalty      : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/finetuning_task                       : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/forced_bos_token_id                   : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/forced_eos_token_id                   : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/id2label                              : {0: 'LABEL_0', 1: 'LABEL_1'}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_composition                        : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_decoder                            : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_encoder_decoder                    : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/label2id                              : {'LABEL_0': 0, 'LABEL_1': 1}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/length_penalty                        : 2.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/max_length                            : 20\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/min_length                            : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/model_type                            : encoder-decoder\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/name_or_path                          : \n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/no_repeat_ngram_size                  : 0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_beam_groups                       : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_beams                             : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_labels                            : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_return_sequences                  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_attentions                     : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_hidden_states                  : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_scores                         : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/pad_token_id                          : 2\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/prefix                                : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/problem_type                          : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/pruned_heads                          : {}\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/remove_invalid_values                 : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/repetition_penalty                    : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/return_dict                           : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/return_dict_in_generate               : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/sep_token_id                          : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/suppress_tokens                       : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/task_specific_params                  : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/temperature                           : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tf_legacy_loss                        : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tie_encoder_decoder                   : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tie_word_embeddings                   : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tokenizer_class                       : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/top_k                                 : 50\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/top_p                                 : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/torch_dtype                           : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/torchscript                           : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/transformers_version                  : None\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/typical_p                             : 1.0\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_bfloat16                          : False\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_return_dict                       : True\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/vocab_size                            : 32000\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n","\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 259 metrics, params and output messages\n"]},{"data":{"text/plain":["TrainOutput(global_step=3900, training_loss=0.5953431080549191, metrics={'train_runtime': 15236.0888, 'train_samples_per_second': 32.817, 'train_steps_per_second': 0.256, 'total_flos': 3.061502154909942e+17, 'train_loss': 0.5953431080549191, 'epoch': 9.980806142034549})"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ikkdkNIn2z79","outputId":"f218eae4-3e32-4845-e190-e2360ae0b8dd"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/willy030125/.venv/lib/python3.10/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:643: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [625/625 00:51]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["results = trainer.evaluate(tokenized_eval)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"anawJFnSG0Kv","outputId":"ff9a9f00-d5b6-47e9-f5a8-e45f80084ca4"},"outputs":[{"data":{"text/plain":["{'eval_loss': 0.5570188760757446,\n"," 'eval_runtime': 52.0718,\n"," 'eval_samples_per_second': 96.021,\n"," 'eval_steps_per_second': 12.003,\n"," 'epoch': 9.980806142034549}"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["results"]},{"cell_type":"code","source":["import math\n","\n","metrics = trainer.evaluate(tokenized_eval)\n","\n","try:\n","    perplexity = math.exp(metrics[\"eval_loss\"])\n","except OverflowError:\n","    perplexity = float(\"inf\")\n","\n","metrics[\"perplexity\"] = perplexity\n","\n","trainer.log_metrics(\"eval\", metrics)\n","trainer.save_metrics(\"eval\", metrics)\n","\n","print(perplexity)"],"metadata":{"id":"l7VS-9SLCrtb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGuHHwLfG0Kw","outputId":"80281c7f-8450-4525-d7a8-3ac279b96532"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'early_stopping': True, 'length_penalty': 2.0}\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:563: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/home/willy030125/.venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:582: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n"]}],"source":["trainer.save_model('./Bert2Bert_trained/')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"059e2906913a4afcbe43f7d86a30331c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0aea801c08eb422bb1aaaf18895aea6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_059e2906913a4afcbe43f7d86a30331c","placeholder":"​","style":"IPY_MODEL_2f30f32af3bc417481fc3d6a68678e8b","value":" 1000/1000 [00:09&lt;00:00, 169.29 examples/s]"}},"10aecbcd12cf427e9f15db12878c7a27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1842d07fef234c97a1ae7c828fc19fae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d17cf514f49e4b06b9f40d221682b691","placeholder":"​","style":"IPY_MODEL_92a615229c4a496ba41cc9bf4eeb6521","value":"Map (num_proc=4): 100%"}},"2f30f32af3bc417481fc3d6a68678e8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3640f38e7beb4ae084cb0e0253b79d9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4238279c927448aca971450c188ec2ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c99d4003d264e2a8b24ffc342b32950":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4facf208d8eb4c07b300a48fa8f3fb83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"712e2117748a4179873e7fc3e7b18ecb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85e7361159984bfa911e1fbda2330e53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1842d07fef234c97a1ae7c828fc19fae","IPY_MODEL_969147b8bf31493bbbb7d89e0656e98e","IPY_MODEL_a7707ef300e54c5fa95de1d637ffaf96"],"layout":"IPY_MODEL_98e70f25c40a410b95e6df23222494ab"}},"8b22723e8045481689225217424ecfb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ecaeed09c32a4caa90b83782524dc468","IPY_MODEL_ff5a37f79d4e4ae48ae1d46f6f73c4a3","IPY_MODEL_0aea801c08eb422bb1aaaf18895aea6a"],"layout":"IPY_MODEL_c7762f4e7a914adcb8e5145f5cb17241"}},"92a615229c4a496ba41cc9bf4eeb6521":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"969147b8bf31493bbbb7d89e0656e98e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3640f38e7beb4ae084cb0e0253b79d9c","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_712e2117748a4179873e7fc3e7b18ecb","value":10000}},"98e70f25c40a410b95e6df23222494ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7707ef300e54c5fa95de1d637ffaf96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c99d4003d264e2a8b24ffc342b32950","placeholder":"​","style":"IPY_MODEL_10aecbcd12cf427e9f15db12878c7a27","value":" 10000/10000 [01:17&lt;00:00, 206.63 examples/s]"}},"aaeecdeeb6d546d6baa645f6dbed2814":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af6050d99aa4427aa048dbbac7edccdb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7762f4e7a914adcb8e5145f5cb17241":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d17cf514f49e4b06b9f40d221682b691":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecaeed09c32a4caa90b83782524dc468":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aaeecdeeb6d546d6baa645f6dbed2814","placeholder":"​","style":"IPY_MODEL_4facf208d8eb4c07b300a48fa8f3fb83","value":"Map (num_proc=4): 100%"}},"ff5a37f79d4e4ae48ae1d46f6f73c4a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af6050d99aa4427aa048dbbac7edccdb","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4238279c927448aca971450c188ec2ad","value":1000}}}}},"nbformat":4,"nbformat_minor":0}